{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **GIẢ LẬP KIẾN TRÚC RANC VỚI TẬP MNIST**"],"metadata":{"id":"GHVGheNRqSZa"}},{"cell_type":"markdown","source":["spike generator, inspired by snntorch spikegen()"],"metadata":{"id":"4NZLvrR3qvSk"}},{"cell_type":"code","source":[],"metadata":{"id":"ZgccsQrjqu8l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cài trực tiếp tealearning từ drive\n","  "],"metadata":{"id":"DJzDOO0br2zf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","# copy software from Google Drive to content\n","# !ln -s \"/gdrive/My Drive/theFolder\" \"/content/theFolder\n","!cp -r /content/gdrive/MyDrive/Colab/software ./"],"metadata":{"id":"yYQobnMPrMPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669422591042,"user_tz":-420,"elapsed":51746,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"647abe94-78ee-43d7-af16-afd76611a0b2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["\n","Tiến hành download toàn bộ code trong đường link này:\n","https://github.com/UA-RCL/RANC/tree/master/software\n","sau đó up lên colab, giải nén\n","\n","Có thể sử dụng link này để download: https://minhaskamal.github.io/DownGit/#/home\n"],"metadata":{"id":"sc2jKO0yYIeT"}},{"cell_type":"code","source":["!unzip \"software.zip\""],"metadata":{"id":"Q6SiX2Ti8m7k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Code này sẽ sử dụng tealayer2.0 (sử dụng tensorflow 2.x)\n","\n","Sau khi giải nén, do code mặc định của họ đang sử dụng tensorflow 2.0.0b1 mà phiên bản đó giờ không còn được hỗ trợ nên cần phải chỉnh lại.\n","\n","=> Truy cập \"./sofware/tealayers/tealayer2.0/setup.py\", chỉnh dòng 19 thành 'tensorflow-gpu==2.7.0' hoặc bất cứ phiên bản 2.x nào đang được hỗ trợ rồi lưu lại"],"metadata":{"id":"56eEv45AYP87"}},{"cell_type":"markdown","source":["Code của họ bị sai ở một đoạn, để sửa:\n","\n","=> Đi đến \"./software/tealayers/tealayer2.0/tealayer2/additivepooling.py\"\n","\n","Sửa dòng 73 thành \"output = tf.reshape(output, [-1, int(self.num_inputs//self.num_classes), self.num_classes])\" rồi lưu lại"],"metadata":{"id":"tsqa8REUaMZv"}},{"cell_type":"code","source":["%cd \"./software\"\n","!pip install \"./tealayers/tealayer2.0\"\n","!pip install \"./rancutils\""],"metadata":{"id":"M23YKlD694fI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1669423527481,"user_tz":-420,"elapsed":7557,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"d28721c2-5365-4379-cb86-1a528ed4b8a3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: './software'\n","/content/software\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./tealayers/tealayer2.0\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: tensorflow-gpu==2.10 in /usr/local/lib/python3.7/dist-packages (from tealayer2==2.0) (2.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tealayer2==2.0) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tealayer2==2.0) (7.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (2.1.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (3.1.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (0.27.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (14.0.6)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (57.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (4.1.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (0.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.50.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (1.14.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (3.3.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (3.19.6)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (0.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (22.11.23)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (2.10.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (2.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.10->tealayer2==2.0) (21.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10->tealayer2==2.0) (0.38.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu==2.10->tealayer2==2.0) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (2.14.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (5.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10->tealayer2==2.0) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu==2.10->tealayer2==2.0) (3.0.9)\n","Building wheels for collected packages: tealayer2\n","  Building wheel for tealayer2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tealayer2: filename=tealayer2-2.0-py3-none-any.whl size=8381 sha256=0d9d6b4000478b5ea19749a406ee60edb988f2d78d0fb36117f0e2d865e88110\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-h8id3zei/wheels/98/3e/d2/fb82202f5627bfe136eb2273610123897f01cae8671052dba2\n","Successfully built tealayer2\n","Installing collected packages: tealayer2\n","  Attempting uninstall: tealayer2\n","    Found existing installation: tealayer2 2.0\n","    Uninstalling tealayer2-2.0:\n","      Successfully uninstalled tealayer2-2.0\n","Successfully installed tealayer2-2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tealayer2"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./rancutils\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rancutils==0.1) (1.21.6)\n","Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (from rancutils==0.1) (4.0.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from rancutils==0.1) (2.9.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from rancutils==0.1) (1.3.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio->rancutils==0.1) (7.1.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->rancutils==0.1) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->rancutils==0.1) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->rancutils==0.1) (1.15.0)\n","Building wheels for collected packages: rancutils\n","  Building wheel for rancutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rancutils: filename=rancutils-0.1-py3-none-any.whl size=9632 sha256=9cbce27014ff4f06bd537949143d943ed20968e22ae54c5ea0809d4c4db9182a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-o2giz29t/wheels/8d/c1/61/148622b68a98f462bf31487b2ede5ce6d3496d99ca12f2f7c1\n","Successfully built rancutils\n","Installing collected packages: rancutils\n","  Attempting uninstall: rancutils\n","    Found existing installation: rancutils 0.1\n","    Uninstalling rancutils-0.1:\n","      Successfully uninstalled rancutils-0.1\n","Successfully installed rancutils-0.1\n"]}]},{"cell_type":"markdown","source":["# **CÀI ĐẶT CÁC THƯ VIỆN CẦN THIẾT**"],"metadata":{"id":"aBM19A2ESIKj"}},{"cell_type":"code","source":["from tealayer2 import Tea, AdditivePooling\n","from tensorflow.keras.layers import Flatten, Activation, Input, Lambda, concatenate\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import Model\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"metadata":{"id":"uHz8iMojSHtI","executionInfo":{"status":"ok","timestamp":1669423314348,"user_tz":-420,"elapsed":412,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# **KHỞI TẠO MẠNG**"],"metadata":{"id":"JiUNlPiLSAEM"}},{"cell_type":"markdown","source":["Xây dựng cấu trúc của mạng\n","\n","kết quả là biến \"network\""],"metadata":{"id":"U4fnmj9i3RYc"}},{"cell_type":"code","source":["# Greyscale images are of shape (28,28,1)\n","inputs = Input(shape=(28,28,1))\n","\n","# Flatten the inputs so that inputs map as: flatten_input[0] -> axon[0], ..., flatten_input[255] -> axon[255]\n","flattened_inputs = Flatten()(inputs)\n","\n","# Generate each core.\n","# We are taking a 16x16 square of the input image and striding it by 12. this gives us 4 cores with 0 padding encumpassing the entire image.\n","# Trải phẳng các ảnh input 28x28x1 thành 1 vector 784x1, quét từng đoạt 256 để đưa vào lần lượt các core, mỗi đoạn sau stride 12 phần tử so với đoạn trước\n","# (Trong chương 02 ở file doc là quét 4 góc bức ảnh, nó cũng tương tự như thế này)\n","core0 = Lambda(lambda x : x[:, :256])(flattened_inputs)\n","core1 = Lambda(lambda x : x[:, 176:432])(flattened_inputs)\n","core2 = Lambda(lambda x : x[:, 352:608])(flattened_inputs)\n","core3 = Lambda(lambda x : x[:, 528:])(flattened_inputs)\n","\n","# Use the image distributions as corresponding inputs into our Tea Layer.\n","# units là số neuron được sử dụng cho tea layer này, ở đây khai báo 4 tea layer với units = 64 (tương ứng 4 core với mỗi core sử dụng 64 neuron)\n","core0 = Tea(units=64, name='tea_1_1')(core0)\n","core1 = Tea(units=64, name='tea_1_2')(core1)\n","core2 = Tea(units=64, name='tea_1_3')(core2)\n","core3 = Tea(units=64, name='tea_1_4')(core3)\n","\n","# The classification is the concatenation of these 4 core's outputs.\n","# We'll call the classification core our 'network'\n","network = concatenate([core0, core1, core2, core3])\n","\n","# Gộp đầu ra của 4 core trên lại thành 1 layer khác (tổng sẽ là 256 đầu vào cho tea layer này), tuy nhiên\n","# do chỉ có 10 class (các số từ 0 đến 9, mỗi số 1 class) => layer này chỉ sử dụng 250 neuron (do 256 không\n","# chia hết cho 10), trong đó cứ 25 neuron thì sẽ vote cho 1 class, số lượng neuron vote cho class nào lớn \n","# nhất thì ảnh sẽ thuộc về class đó. Ví dụ trong 250 đầu ra, từ 0 đến 24 có 17 spike bắn ra, đồng thời \n","# không có cụm nào bắn ra được nhiều bằng hoặc hơn 17 => Ảnh thuộc về class số \"0\" \n","network = Tea(units=250, name='tea_2')(network)\n","\n","network = AdditivePooling(10)(network)\n","print(network)"],"metadata":{"id":"bcghk_23SXWz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669425246066,"user_tz":-420,"elapsed":1121,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"be3d7cb8-d545-4a93-98fb-fdd4295c27fb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"additive_pooling/Sum:0\", shape=(?, 10), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["# **TRAIN MODEL**"],"metadata":{"id":"ZAS5HF-dV4ET"}},{"cell_type":"markdown","source":["Lấy ảnh từ tập ảnh mnist và tạo 2 mẫu ảnh train và test\n","\n","Xử lý ảnh train\n","\n","Đưa mẫu ảnh train và cấu trúc mạng vào bắt đầu train. Sau đó thu được \"model\" đã train"],"metadata":{"id":"EOEjyeaR3hpG"}},{"cell_type":"markdown","source":["### Input trực tiếp ảnh"],"metadata":{"id":"ezldkW4qThD2"}},{"cell_type":"code","source":["# Chuẩn bị dataset để train\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(X_train.shape)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","print(y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIZelP52Wbc-","executionInfo":{"status":"ok","timestamp":1669422793566,"user_tz":-420,"elapsed":999,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"0d219938-3520-477a-b285-1a6ccd6f9d11"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n","(60000, 28, 28)\n","(10000, 10)\n"]}]},{"cell_type":"code","source":["# start \"softmax\" function\n","predictions = Activation('softmax')(network)\n","\n","model = Model(inputs=inputs, outputs=predictions)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","X_train = X_train.reshape(-1, 28, 28, 1)\n","X_test = X_test.reshape(-1, 28, 28, 1)\n","\n","model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n","\n","score = model.evaluate(X_test, y_test, verbose=0)\n","\n","print(\"Test Loss: \", score[0])\n","print(\"Test Accuracy: \", score[1])"],"metadata":{"id":"dgyBxubCR_EB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668594169400,"user_tz":-420,"elapsed":17725,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"f243b8a2-f27d-4d75-ebc3-4cbf3283cc67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 10)\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/10\n","48000/48000 [==============================] - 2s 37us/sample - loss: 0.0993 - acc: 0.9682 - val_loss: 0.2153 - val_acc: 0.9318\n","Epoch 2/10\n","48000/48000 [==============================] - 2s 33us/sample - loss: 0.0931 - acc: 0.9693 - val_loss: 0.2044 - val_acc: 0.9350\n","Epoch 3/10\n","48000/48000 [==============================] - 2s 34us/sample - loss: 0.0920 - acc: 0.9701 - val_loss: 0.2235 - val_acc: 0.9299\n","Epoch 4/10\n","48000/48000 [==============================] - 2s 33us/sample - loss: 0.0876 - acc: 0.9716 - val_loss: 0.1859 - val_acc: 0.9395\n","Epoch 5/10\n","48000/48000 [==============================] - 2s 33us/sample - loss: 0.0863 - acc: 0.9716 - val_loss: 0.2086 - val_acc: 0.9370\n","Epoch 6/10\n","48000/48000 [==============================] - 2s 33us/sample - loss: 0.0869 - acc: 0.9724 - val_loss: 0.2013 - val_acc: 0.9405\n","Epoch 7/10\n","48000/48000 [==============================] - 2s 32us/sample - loss: 0.0842 - acc: 0.9733 - val_loss: 0.1911 - val_acc: 0.9385\n","Epoch 8/10\n","48000/48000 [==============================] - 2s 32us/sample - loss: 0.0841 - acc: 0.9730 - val_loss: 0.1964 - val_acc: 0.9408\n","Epoch 9/10\n","48000/48000 [==============================] - 2s 33us/sample - loss: 0.0836 - acc: 0.9725 - val_loss: 0.1845 - val_acc: 0.9428\n","Epoch 10/10\n","48000/48000 [==============================] - 2s 32us/sample - loss: 0.0789 - acc: 0.9736 - val_loss: 0.1989 - val_acc: 0.9340\n","Test Loss:  0.19059836150705814\n","Test Accuracy:  0.9415\n"]}]},{"cell_type":"markdown","source":["### Encode ảnh"],"metadata":{"id":"4domlwkLTnhr"}},{"cell_type":"code","source":["from tealayer2 import helper_functions\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","# Normalizing pixel value between 0 and 1.\n","X_train /= 255\n","X_test /= 255\n","\n","X_train_encode = X_train.reshape(X_train.shape[0], (28*28))\n","X_test_encode = X_test.reshape(X_test.shape[0], (28*28))\n","# Chuẩn bị dataset để train\n","x_train_encoded = helper_functions.encode_dataset(X_train_encode, ticks = 4, method = 'rate encoding')\n","x_test_encoded = helper_functions.encode_dataset(X_test_encode, ticks = 4, method = 'rate encoding')\n","print(x_train_encoded.shape)\n","#x_test_encoded = ranc_encode_burst_rate(x_test, 1, (46, 46)).reshape(x_test.shape[0], 1, 46, 46)\n","\n","#X_test /= 255\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mxqUO0lbgop","executionInfo":{"status":"ok","timestamp":1669426325871,"user_tz":-420,"elapsed":578806,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"40bd4d93-5b16-448f-a9b3-782aee0c5ca5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 4, 784)\n"]}]},{"cell_type":"code","source":["x_train_encoded = x_train_encoded.reshape(x_train_encoded.shape[0], 28, 28, x_train_encoded.shape[1])\n","\n","print(x_train_encoded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"3Bd35Q95dNcD","executionInfo":{"status":"error","timestamp":1669426325872,"user_tz":-420,"elapsed":50,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"0e05026b-22a7-476f-d42d-9bc127efd579"},"execution_count":21,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-049c2e25f173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 31360000 into shape (10000,28,28,28)"]}]},{"cell_type":"code","source":["x_test_encoded = x_test_encoded.reshape(x_test_encoded.shape[0], 28, 28, x_test_encoded.shape[1])"],"metadata":{"id":"xL4ymvvFma7-","executionInfo":{"status":"ok","timestamp":1669426968506,"user_tz":-420,"elapsed":1,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["x_train_encoded = x_train_encoded.reshape(60000, 28, 28, 4)\n","x_test_encoded = x_test_encoded.reshape(10000, 28, 28, 4)\n","print(x_train_encoded.shape)\n","print(x_test_encoded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFAeFzK6mgKh","executionInfo":{"status":"ok","timestamp":1669427187549,"user_tz":-420,"elapsed":8,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"fc79266e-5c7f-4e89-d6e5-1c7ac3e31680"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28, 4)\n","(10000, 28, 28, 4)\n"]}]},{"cell_type":"code","source":["# start \"softmax\" function\n","predictions = Activation('softmax')(network)\n","\n","model = Model(inputs=inputs, outputs=predictions)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","x_train_encoded = x_train_encoded.reshape(60000, 4, 28, 28, 1)\n","x_test_encoded = x_test_encoded.reshape(10000, 4, 28, 28, 1)\n","model.fit(x_train_encoded, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n","\n","score = model.evaluate(X_test, y_test, verbose=0)\n","\n","print(\"Test Loss: \", score[0])\n","print(\"Test Accuracy: \", score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"executionInfo":{"status":"error","timestamp":1669427303694,"user_tz":-420,"elapsed":472,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"39c076ba-75bc-4b92-f86f-5818f84326d9","id":"IfcziD9IdNou"},"execution_count":29,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-bedd9e1067a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         )\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         )\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m         )\n\u001b[1;32m   2659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2693\u001b[0m                 \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m                 \u001b[0mexception_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m             )\n\u001b[1;32m   2697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    720\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0;34m\" dimensions, but got array \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                         \u001b[0;34m\"with shape \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m                     )\n\u001b[1;32m    724\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (60000, 4, 28, 28, 1)"]}]},{"cell_type":"markdown","source":["# **GENERATE MẠNG VÀ CÁC PACKET**"],"metadata":{"id":"pmLElL37WP5O"}},{"cell_type":"code","source":["# Optionally, then save the generated network out for use in the simulator and/or hardware\n","from rancutils.teaconversion import create_cores, create_packets, Packet\n","from rancutils.output_bus import OutputBus\n","from rancutils.serialization import save as sim_save\n","\n","x_test_flat = X_test.reshape((10000, 784))\n","partitioned_packets = []\n","\n","#test với 10000 ảnh\n","num_test_samples = 10\n","# Tạo các core bằng hàm create_cores(), sử dụng 2 layer (1 layer 4 core và 1 layer 1 core), sử dụng absolute reset mode: neuron_reset_type=0\n","cores_sim = create_cores(model, 2, neuron_reset_type=0) \n","# Partition the packets into groups as they will be fed into each of the input cores\n","partitioned_packets.append(x_test_flat[:num_test_samples, :256])\n","partitioned_packets.append(x_test_flat[:num_test_samples, 176:432])\n","partitioned_packets.append(x_test_flat[:num_test_samples, 352:608])\n","partitioned_packets.append(x_test_flat[:num_test_samples, 528:])\n","# Tạo packet bằng hàm create_packets()\n","packets_sim = create_packets(partitioned_packets)\n","# Tạo output_bus bằng hàm OutputBus(coordinate, num_outputs)\n","output_bus_sim = OutputBus((0, 2), num_outputs=250)\n","\n","# Đây chính là file đầu vào cho giả lập kiến trúc RANC bằng code C++\n","sim_save(\"mnist_config.json\", cores_sim, packets_sim, output_bus_sim, indent=2)\n","# Lưu lại đầu ra của tensorflow predictions và correct labels để tý làm cross validation\n","predict = model.predict(X_test[:num_test_samples,:])\n","idx = []\n","for i in predict:\n","  idx.append(np.argmax(i))\n","test_predictions = to_categorical(idx)\n","np.save(\"mnist_tf_preds.txt\", test_predictions)\n","np.save(\"mnist_correct_preds.txt\", y_test[:num_test_samples,:])"],"metadata":{"id":"8UFj0wDIWQeo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da5a0129-1c89-47b1-b52e-fb6bac40fde4","executionInfo":{"status":"ok","timestamp":1667902146952,"user_tz":-420,"elapsed":703,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]}]},{"cell_type":"markdown","source":["**Lưu file mem**"],"metadata":{"id":"wx6tZ5Q-CP4j"}},{"cell_type":"code","source":["from rancutils.emulation import output_for_testbench, output_for_streaming"],"metadata":{"id":"md4ZlYjh2O-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_for_streaming(cores_sim,max_xy=(4,2),output_path=\"/content/mnist_5_core_mem\")"],"metadata":{"id":"N7iT10JZ3WMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/mnist_5_core_mem.zip /content/mnist_5_core_mem"],"metadata":{"id":"CRr4H69RIY_G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667902201841,"user_tz":-420,"elapsed":585,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}},"outputId":"32e7255d-6836-4ce2-cf88-7fb100363cfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/mnist_5_core_mem/ (stored 0%)\n","  adding: content/mnist_5_core_mem/tc_005.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/tc_001.mem (deflated 98%)\n","  adding: content/mnist_5_core_mem/csram_003.mem (deflated 96%)\n","  adding: content/mnist_5_core_mem/tc_004.mem (deflated 98%)\n","  adding: content/mnist_5_core_mem/csram_001.mem (deflated 96%)\n","  adding: content/mnist_5_core_mem/csram_000.mem (deflated 96%)\n","  adding: content/mnist_5_core_mem/csram_002.mem (deflated 96%)\n","  adding: content/mnist_5_core_mem/tc_007.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/tc_000.mem (deflated 98%)\n","  adding: content/mnist_5_core_mem/tc_003.mem (deflated 98%)\n","  adding: content/mnist_5_core_mem/csram_005.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/csram_007.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/csram_004.mem (deflated 87%)\n","  adding: content/mnist_5_core_mem/csram_006.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/tc_006.mem (deflated 99%)\n","  adding: content/mnist_5_core_mem/tc_002.mem (deflated 98%)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/mnist_5_core_mem.zip\")"],"metadata":{"id":"Y8kSJmDbIbJY","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"213c9981-589d-42e7-a243-5e80d4ee262f","executionInfo":{"status":"ok","timestamp":1667902207812,"user_tz":-420,"elapsed":675,"user":{"displayName":"Tâm Trần Đức","userId":"06468723492313726316"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_35e30873-0d5d-44d5-98ec-ef6c22828812\", \"mnist_5_core_mem.zip\", 32201)"]},"metadata":{}}]},{"cell_type":"markdown","source":["**Lưu input và output chuẩn**"],"metadata":{"id":"WUKca9YCCUiD"}},{"cell_type":"code","source":["# lưu input và output chuẩn\n","output_for_testbench(packets_sim,\n","                         y_test[:num_test_samples,:],\n","                         output_path='/content/',\n","                         input_filename='tb_input.txt',\n","                         correct_filename='tb_correct.txt',\n","                         num_inputs_filename='tb_num_inputs.txt',\n","                         num_outputs_filename='tb_num_outputs.txt',\n","                         max_packet_xy=(512, 512),\n","                         num_axons=256,\n","                         num_ticks=16,\n","                         num_outputs=250)"],"metadata":{"id":"OipnSEtm00GU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sau khi chạy xong đoạn code này, 3 file mới sẽ được tạo ra. Tiến hành tải file \"mnist_config.json\" về để làm input file cho code RANC simulator C++"],"metadata":{"id":"NXUTG5vJdpsV"}},{"cell_type":"markdown","source":["# **C++**"],"metadata":{"id":"_7iP2MulazDV"}},{"cell_type":"markdown","source":["**Compile code**"],"metadata":{"id":"59mywRAGsLK2"}},{"cell_type":"code","source":["cd \"/content/\""],"metadata":{"id":"JRkhibSsbOqL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4fcdf75-243f-46e8-e1a2-95a1676c6461"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!unzip \"simulator.zip\""],"metadata":{"id":"eyVAzbOrZG_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd \"./simulator/\""],"metadata":{"id":"al1m8tDOba2r","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e861fe6-31e6-4e31-88cc-27cba0a8d0bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/simulator\n"]}]},{"cell_type":"code","source":["!mkdir build"],"metadata":{"id":"bPRlcKqWb_Ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd build"],"metadata":{"id":"8jpMr4FCbbUo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"79dd487a-035e-4ec3-bd04-b1b75b128345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/simulator/build\n"]}]},{"cell_type":"code","source":["!cmake \"..\"\n","!make"],"metadata":{"id":"O_IM4WGXcBbB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Chạy code**"],"metadata":{"id":"MVd3VwY9sO_K"}},{"cell_type":"markdown","source":["Muốn chạy với x ảnh thì số tick là x + 2, do trễ 2 tick từ 2 layer"],"metadata":{"id":"3Ddsl-uhsdWK"}},{"cell_type":"code","source":["!/content/simulator/build/ranc_sim -i /content/software/mnist_config.json -o /content/simulator_output.txt -c /content/simulator/config.json 12"],"metadata":{"id":"L3vAU8dIdZfz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **SO SÁNH ĐẦU RA TỪ SIMULATOR VỚI ĐẦU RA CỦA TENSORFLOW**"],"metadata":{"id":"3G_YgDCic2HH"}},{"cell_type":"markdown","source":["Tiến hành upload file output của simulator lên colab, chạy đoạn code này để so sánh\n","\n","Lưu ý:\n","\n","- Tên file đặt là \"simulator_output.txt\" và lưu trong đường dẫn hiện tại đang cd đến\n","\n","- Trước khi upload, xóa 2 dòng đầu tiên trong file output đi (chi tiết trong file doc)"],"metadata":{"id":"Po2QXAUZeVDp"}},{"cell_type":"code","source":["    # TODO: Add usage example for outputting to emulation via rancutils.emulation.write_cores, etc.\n","\n","    ###\n","    # ...\n","    # Start the simulator, etc, and collect results...\n","    # ...\n","    ###\n","\n","    # Process the output to collect final classificaiton results and compare against Tensorflow predictions\n","    from rancutils.simulator import collect_classifications_from_simulator\n","    tf_output = np.load(\"/content/software/mnist_tf_preds.txt\"+\".npy\")\n","    correct_output = np.load(\"/content/software/mnist_correct_preds.txt\"+\".npy\")\n","    simulator_output = collect_classifications_from_simulator(\"/content/simulator_output.txt\", num_classes=10)\n","    \n","    tf_output_flat = np.array([0] * tf_output.shape[0])\n","    for i in range(tf_output.shape[0]):\n","        output_i = tf_output[i, :]\n","        decision = np.where(output_i == max(output_i))[0]\n","        if len(decision) > 1:\n","            decision = decision[0]\n","        tf_output_flat[i] = decision\n","    tf_output = tf_output_flat\n","    \n","    correct_output_flat = np.array([0] * correct_output.shape[0])\n","    for i in range(correct_output.shape[0]):\n","        output_i = correct_output[i, :]\n","        decision = np.where(output_i == max(output_i))[0]\n","        if len(decision) > 1:\n","            decision = decision[0]\n","        correct_output_flat[i] = decision\n","    correct_output = correct_output_flat\n","\n","    if all(tf_output == simulator_output):\n","        print(\"Tensorflow output matches simulator output exactly!\")\n","        print(f\"Testing accuracy against known class labels is {(len(np.where(tf_output == correct_output[:len(tf_output)])[0]) / len(tf_output)) * 100}%\")\n","    else:\n","        print(\"There are differences between Tensorflow and the simulator...\")\n","        print(f\"Differences are in indices {np.where(tf_output != simulator_output)}\")\n","        print(f\"Tensorflow thought the classes were {tf_output[np.where(tf_output != simulator_output)]}\")\n","        print(f\"The simulator thought the classes were {simulator_output[np.where(tf_output != simulator_output)]}\")\n","        print(f\"The correct classes were {correct_output[np.where(tf_output != simulator_output)]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f69lEYcm-S-s","outputId":"3c144646-a3d3-471c-df0a-b3a6a9f006aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow output matches simulator output exactly!\n","Testing accuracy against known class labels is 90.0%\n"]}]}]}